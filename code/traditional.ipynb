{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121f8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pricer.evaluator import evaluate\n",
    "from pricer.items import Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab60a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LITE_MODE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da32571",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"ed-donner\"\n",
    "dataset = f\"{username}/items_lite\" if LITE_MODE else f\"{username}/items_full\"\n",
    "\n",
    "train, val, test = Item.from_hub(dataset)\n",
    "\n",
    "print(f\"Loaded {len(train):,} training items, {len(val):,} validation items, {len(test):,} test items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f24e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_pricer(item):\n",
    "    return random.randrange(1,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a709f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "evaluate(random_pricer, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194e6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We can do better - here's another rather trivial model\n",
    "\n",
    "training_prices = [item.price for item in train]\n",
    "training_average = sum(training_prices) / len(training_prices)\n",
    "print(training_average)\n",
    "\n",
    "def constant_pricer(item):\n",
    "    return training_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af837266",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(constant_pricer, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402d104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(item):\n",
    "    return {\n",
    "        \"weight\": item.weight,\n",
    "        \"weight_unknown\": 1 if item.weight==0 else 0,\n",
    "        \"text_length\": len(item.summary)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e3680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_dataframe(items):\n",
    "    features = [get_features(item) for item in items]\n",
    "    df = pd.DataFrame(features)\n",
    "    df['price'] = [item.price for item in items]\n",
    "    return df\n",
    "\n",
    "train_df = list_to_dataframe(train)\n",
    "test_df = list_to_dataframe(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b67c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional Linear Regression!\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Separate features and target\n",
    "feature_columns = ['weight', 'weight_unknown', 'text_length']\n",
    "\n",
    "X_train = train_df[feature_columns]\n",
    "y_train = train_df['price']\n",
    "X_test = test_df[feature_columns]\n",
    "y_test = test_df['price']\n",
    "\n",
    "# Train a Linear Regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "for feature, coef in zip(feature_columns, model.coef_):\n",
    "    print(f\"{feature}: {coef}\")\n",
    "print(f\"Intercept: {model.intercept_}\")\n",
    "\n",
    "# Predict the test set and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fcd5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_pricer(item):\n",
    "    features = get_features(item)\n",
    "    features_df = pd.DataFrame([features])\n",
    "    return model.predict(features_df)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98aa022",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(linear_regression_pricer, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20a3dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = np.array([float(item.price) for item in train])\n",
    "documents = [item.summary for item in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b4f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "vectorizer = CountVectorizer(max_features=2000, stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324820ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the 1,000 most common words that it picked, not including \"stop words\":\n",
    "\n",
    "selected_words = vectorizer.get_feature_names_out()\n",
    "print(f\"Number of selected words: {len(selected_words)}\")\n",
    "print(\"Selected words:\", selected_words[1000:1020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398641c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X, prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aae9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
